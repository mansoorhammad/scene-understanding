## Multi-Task Deep Learning Frameworks for Abstracting Visual Information

### Abstract
<p align="justify">
Scene Understanding involves a computer being able to understand the relative positions of objects within an image and the semantic relationships between them. It gives the computer a holistic understanding of the scene to make decisions in subsequent processing stages. Our project is aimed at building a system that can receive live video input for an indoor scene and perform three important scene understanding tasks: object detection, semantic segmentation, and image caption generation. The output of each of these subsystems is displayed together on a GUI with the corresponding live video feed. For the object detection task, we use a pre-trained YOLOv8 model that can localize object classes present in an image and build bounding boxes around them. Our Instance Segmentation model is also based on the architecture of the YOLOv8 model, tailored for recognizing and categorizing each pixel of indoor objects into distinct classes. Finally, the image captioning model is based on an encoder-decoder architecture that consists of the Vision Transformer and EfficientNetB0 algorithms, capable of analyzing semantic relations between objects and giving textual descriptions of activity within the image. All three models will run in parallel on video input from a tablet/laptop camera and each output will be displayed on one of four sections of a GUI that is built using Flask. The development of such a system is pivotal for applications in autonomous vehicles, indoor navigation, and localization, as well as enhancing security systems by providing continuous monitoring and logging of activities within a specified area.
</p>

